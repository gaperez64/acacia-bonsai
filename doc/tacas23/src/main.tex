\documentclass[runningheads,a4paper]{llncs}
\usepackage[english]{babel}
\usepackage{xspace}
% \usepackage[ruled,vlined,nosemicolon]{algorithm2e}
\usepackage{pbox}
\usepackage{float}
\usepackage{tikz}
\usepackage{paralist}
\usepackage[inline]{enumitem}
\usepackage{amssymb,amstext,amsmath}
\usepackage{mathtools}
\usepackage{cleveref}

\newif\ifanon
\anonfalse

\usetikzlibrary{hobby,calc}

\input{define.orgtex}

\begin{document}

\title{Acacia-Bonsai: A Modern Implementation of Downset-Based LTL Realizability}
\titlerunning{Acacia-Bonsai: Downset-Based LTL Realizability}

\ifanon
  \DeclareRobustCommand*\anon[1]{\anonymize{#1}}%\colorbox{black!50}{\phantom{\pbox{\textwidth}{#1}}}}
\else
  \def\anon#1{#1}
\fi

 \author{\anon{Micha\"el Cadilhac\inst{1}\orcidID{0000-0001-9828-9129}
         \and \anon{Guillermo A. P\'erez\inst{2}\orcidID{0000-0002-1200-4952}}}}
\institute{\anon{DePaul University, Chicago, USA}\\
 \anon{\email{michael@cadilhac.name}} \and
 \anon{University of Antwerp -- Flanders Make, Antwerp, Belgium}\\
 \anon{\email{guillermo.perez@uantwerp.be}}
}
\authorrunning{\anon{M. Cadilhac \and G. A. P\'erez}}

\maketitle

\begin{abstract}
  We describe our implementation of downset-manipulating algorithms used to solve the
  realizability problem for linear temporal logic (LTL). These algorithms were
  introduced by Filiot et al.~in the 2010s and implemented in the tools Acacia
  and Acacia+ in C and Python.  We identify degrees of freedom in the original
  algorithms and provide a complete rewriting of Acacia in C++20 articulated
  around genericity and leveraging modern techniques for better performance.
  These techniques include compile-time specialization of the algorithms, the
  use of SIMD registers to store vectors, and several preprocessing steps, some
  relying on efficient Binary Decision Diagram (BDD) libraries.  We also explore
  different data structures to store downsets.  The resulting tool is
  competitive against comparable modern tools.
  \keywords{LTL synthesis \and C++ \and downset \and antichains \and SIMD \and BDD}
\end{abstract}

\section{Introduction}

Nowadays, hardware and software systems are everywhere around us. One way to
ensure their correct functioning is to automatically synthesize them from a
formal specification.  This has two advantages over alternatives such as
testing and model checking: the design part of the program-development process
can be completely bypassed and the synthesized program is correct by
construction.

In this work we are interested in synthesizing \emph{reactive
systems}~\cite{hp84}. These maintain a continuous interaction with their
environment.  Examples of reactive systems include communication, network, and
multimedia protocols as well as operating systems.  For the specification, we
consider \emph{linear temporal logic} (LTL)~\cite{pnueli77}. LTL allows to
naturally specify time dependence among events that make up the formal
specification of a system. The popularity of LTL as a formal specification
language extends to, amongst others, AI~\cite{gv16,cm19,gnpw20}, hybrid
systems and control~\cite{bvpyb16}, software engineering~\cite{lpb15}, and
bio-informatics~\cite{abbdfhinprs17}.

The classical doubly-exponential-time synthesis algorithm can be decomposed
into three steps:
\begin{enumerate*}
  \item \emph{compile} the LTL formula into an automaton of exponential
    size~\cite{vw84},
  \item \emph{determinize} the automaton~\cite{safra88,piterman07} incurring a
    second exponential blowup, and
  \item determine the winner of a \emph{two-player zero-sum game} played
    on the latter automaton~\cite{pr89}.
\end{enumerate*}
Most alternative approaches focus on avoiding the determinization step of the
algorithm. This has motivated the development of so-called Safra-less
approaches, e.g.,~\cite{kpv06,eks16,ekrs17,tushy17}. Worth mentioning are the
on-the-fly game construction implemented in the Strix tool~\cite{msl18} and
the \emph{downset}-based (or ``antichain-based'') on-the-fly bounded
determinization described in~\cite{fjr09} and implemented in
Acacia+~\cite{bbfjr12}. Both avoid constructing the doubly-exponential
deterministic automaton.  Acacia+ was not ranked in recent editions of
SYNTCOMP~\cite{syntcomp17} (see \url{http://www.syntcomp.org/}) since it is no longer
maintained despite remaining one of the main references for new advancements
in the field (see, e.g.,~\cite{ffrt17,ztlpv17,apsec20,lms20,bltv20}).

\paragraph*{Contribution.}
We present the Acacia approach to solving the problem at hand and propose a
new implementation that allows for a variety of optimization steps.  For now,
we have focused on \emph{(B\"uchi automata) realizability}, i.e., the decision
problem which takes as input an automaton compiled from the LTL formula and
asks whether a controller satisfying it exists. In our tool, we compile the
input LTL formula into an automaton using Spot~\cite{duret.16.atva2}.  We
entirely specialize our presentation on the technical problem at hand and
strive to distillate the algorithmic essence of the Acacia approach in that
context. The main algorithm is presented in Section~\ref{sec:algo} and the
different implementation options are listed in Section~\ref{sec:implem}.
Benchmarks are included in Section~\ref{sec:benchmarks}.

All benchmarks were executed on the revision of the software that can be found at:
\anon{\url{https://github.com/gaperez64/acacia-bonsai/tree/SYNTCOMP22}}.

\section{Preliminaries}

Throughout this paper, we assume the existence of two alphabets, \(I\) and
\(O\); although these stand for input and output, the actual definitions of
these two terms is slightly more complex: An \emph{input} (\resp
\emph{output}) is a boolean combination of symbols of \(I\) (\resp $O$) and it
is \emph{pure} if it is a \emph{conjunction} in which \emph{all} the symbols
in \(I\) (\resp $O$) appear exactly once; e.g., with \(I = \{i_1, i_2\}\), the
expressions \(\top\) (true), \(\bot\) (false), and \((i_1 \lor i_2)\) are
inputs, and \((i_1 \land \neg i_2)\) is a pure input. Similarly, an \emph{IO}
is a boolean combination of symbols of \(I \cup O\), and it is \emph{pure} if
it is a conjunction in which all the symbols in \(I \cup O\) appear exactly
once.  We use \(i, j\) to denote inputs and \(x, y\) for IOs.  Two IOs \(x\)
and \(y\) are \emph{compatible} if \(x \land y \neq \bot\).

A \emph{Büchi automaton} \cA is a tuple \((Q, q_0, \delta, B)\) with \(Q\) a
set of states, \(q_0\) the initial state, \(\delta\) the transition relation
that uses IOs as labels, and \(B \subseteq Q\) the set of Büchi states.  The
actual semantics of this automaton will not be relevant to our exposition, we
simply note that these automata are usually defined to recognize infinite
sequences of pure IOs.  We assume, throughout this paper, the existence of
some automaton \(\cA\).

We will be interested in valuations of the states of \(\cA\) that encode the
number of visits to
%indicate some
%sort of progress towards reaching 
Büchi states---again, we do not go into details
here.  We will simply speak of \emph{vectors over \cA} for elements in
\(\bbZ^Q\), mapping states to integers.  We will write \(\vec{v}\) for such vectors,
and \(v_q\) for its value for state \(q\).  In practice, these vectors will range
into a finite subset of \(\bbZ\), with \(-1\) as an implicit minimum value (meaning
that \((-1) - 1\) is still \(-1\)) and an upper bound provided by the problem.

For a vector \(\vec{v}\) over \(\cA\) and an IO \(x\), we define a function that takes
one step back in the automaton, decreasing components that have seen Büchi
states.  Write \(\chi_B(q)\) for the function mapping a state \(q\) to \(1\) if
\(q \in B\), and \(0\) otherwise.  We then define \(\bwd(\vec{v}, x)\) as the vector
over \cA that maps each state \(p \in Q\) to:
\[\min_{\substack{(p, y, q) \in \delta\\ x \text{ compatible with } y}} \left(v_q -
  \chi_B(q)\right)\enspace,\]
and we generalize this to sets: \(\bwd(S, x) = \{\bwd(\vec{v}, x) \mid \vec{v}
\in S\}\).
%
For a set \(S\) of vectors over \cA and a (possibly nonpure) input \(i\), define:
\[\cpre_i(S) = S \cap \bigcup_{\substack{x \text{ pure IO}\\x \text{ compatible with } i}} \bwd(S, x)\enspace.\]

It can be proved that iterating \cpre with any possible pure input stabilizes to
a fixed point that is independent from the order in which the inputs are
selected.  We define \(\cpre^*(S)\) to be that set.

All the sets that we manipulate will be \emph{downsets}: we say that a vector
\(\vec{u}\) dominates another vector \(\vec{v}\) if for all \(q \in Q\),
\(u_q \geq v_q\), and we say that a set is a downset if \(\vec{u} \in S\) and
\(\vec{u}\) dominates \(\vec{v}\) implies that \(\vec{v} \in S\).  This allows to
implement these sets by keeping only dominating elements, which form, as they
are pairwise nondominating, an \emph{antichain}.  In practice, it may be
interesting to keep more elements than just the dominating ones or even to keep
all of the elements to avoid the cost of computing domination.

Finally, we define \(\safe_k\) as the downset \(\{i \mid i \leq k\}^Q\), i.e., all vectors
with values bounded by \(k\).
We are now equipped to define the computational problem we focus on:\\[0.5em]
\textbf{BackwardRealizability}
\begin{compactitem}
\item \textbf{Given:} A Büchi automaton \cA and an integer \(k > 0\),
\item \textbf{Question:} Is there a \(\vec{v} \in \cpre^*(\safe_k)\) with \(v_{q_0} \geq
  0\)?
\end{compactitem}

\vspace{0.5em}

We note, for completeness, that (for sufficiently large values of $k$) this
problem is equivalent to deciding the realizability problem associated with
\cA: the question has a positive answer if and only if the \emph{output player} wins the
Gale-Stewart game with payoff set the \emph{complement} of the language of \(\cA\).

\section{Realizability algorithm}

The problem admits a natural algorithmic solution: start with the initial set,
pick an input \(i\), apply \(\cpre_i\) on the set, and iterate until all
inputs induce no change to the set, then check whether this set contains a
vector that maps \(q_0\) to \(0\).  We first introduce some degrees of freedom
in this approach, then present a slight twist on that solution that will serve
as a canvas for the different optimizations.

\subsection{Boolean states}

This opportunity for optimization was identified in \cite{bohy14} and
implemented in Acacia+, we simply introduce it in a more general setting and
succinctly present the original idea when we mention how it
%this optimization 
can be implemented in
Section~\ref{sec:implem-bool}.  We start with an example.  Consider the
Büchi automaton from \Cref{fig:smallauto} with $q_0,q_1 \not\in B$.

\pgfmathsetseed{41}
\tikzset{
 pics/blob/.style={
   code={
   \draw[use Hobby shortcut, fill, closed] (0,0) +($(0:1+4*rnd)$)
       \foreach \a in {60,120,...,350} {  .. +($(\a: 1+4*rnd)$) };
   }
}}

\begin{figure}[h]
  \centering
  \begin{smallautomaton}
    \node[smallstate,initial] (q0) {\(q_0\)};
    \node[smallstate, right of=q0] (q1) {\(q_1\)};
    \path pic[right=1.1cm of q1,smallstate,scale=0.15,dashed] {blob};
    \node[right of=q1] (r) {};

    \path[->] (q0) edge node {\(\top\)} (q1) (q1) edge node {\(\top\)} (r);
  \end{smallautomaton}
  \caption{Small automaton with $q_0,q_1 \not\in B$.}
  \label{fig:smallauto}
\end{figure}

Recall that we are interested in whether the initial state can carry a
nonnegative value, after \cpre has stabilized.  In that sense, the crucial
information associated with \(q_0\) is boolean in nature: is its value positive or
\(-1\)?  Even further, this same remark can be applied to \(q_1\) since \(q_1\) being
valued \(6\) or \(7\) is not important to the valuation of \(q_0\).  Hence the set of
states may be partitioned into integer-valued states and boolean-valued ones.
Naturally, detecting which states can be made boolean comes at a
cost %and this is not necessary for correctness,
and not doing it is a valid option.

\subsection{Actions}

For each IO \(x\), we will have to compute \(\bwd(\vec{v}, x)\) oftentimes.  This
requires to refer to the underlying Büchi automaton and checking for each
transition therein whether \(x\) is compatible with the condition.  It may be
preferable to precompute, for each \(x\), what are the relevant pairs \((p, q)\) for
which \(x\) can go from \(p\) to \(q\).  We call the set of such pairs the
\emph{io-action} of \(x\) and denote it \(\ioact(x)\); in symbols:
\[\ioact(x) = \{(p, q) \mid (\exists (p, y, q) \in \delta)[x \text{ is compatible with }
y]\}\enspace.\]

Further, as we will be computing \(\cpre_i(S)\) for inputs \(i\), we abstract in a
similar way the information required for this computation.  We use the term
\emph{input-action} for the set of io-actions of IOs compatible with \(i\) and denote
it \(\iact(i)\); in symbols:
\[\iact(i) = \bigcup_{\substack{x \text{ an IO}\\\text{compatible with }i}} \ioact(x) \enspace.\]

In other words, actions contain exactly the information necessary to compute
\(\cpre\).  Note that from an implementation point of view, we do not require that
the actions be precomputed.  Indeed, when iterating through pairs
\((p, q) \in \ioact(x)\), the underlying implementation can choose to go back to the
automaton.

\subsection{Sufficient inputs}\label{sec:sufficient}

As we consider the transitions of the Büchi automaton as being labeled by
boolean expressions, it becomes more apparent that some pure IOs can be
redundant.  For instance, consider a Büchi automaton with
\(I = \{i\}, O = \{o_1, o_2\}\), but the only transitions compatible with \(i\) are
labeled \((i \land o_1)\) and \((i \land \neg o_1)\).  Pure IOs compatible with the first
label will be \((i \land o_1 \land o_2)\) and \((i \land o_1 \land \neg o_2)\), but
certainly, these two IOs have the same io-actions, and optimally, we would only
consider \((i \land o_1)\).  However, we should not consider \((i \land o_2)\), as
it induces an io-action that is not induced by a pure IO.  We will
thus allow our main algorithm to select certain inputs and IOs and introduce the
following notion:
\begin{definition}
  An IO (\resp input) is \emph{valid} if there exists any pure IO (\resp input)
  with the same io-action (\resp input-action).  A set \(X\) of valid IOs is
  \emph{sufficient} if it represents all the possible io-actions of pure IOs:
  \(\{\ioact(x) \mid x \in X\} = \{\ioact(x) \mid x \text{ is a pure IO}\}.\) A sufficient
  set of inputs is defined similarly with input-actions.
\end{definition}

\subsection{Algorithm}\label{sec:algo}

We
%Algorithm~\ref{main_algo} solves 
solve \textbf{BackwardRealizability} by computing
\(\cpre^*\) explicitly:

\begin{algorithm}
\caption{Main algorithm}\label{main_algo}
\alginput A Büchi automaton \cA, an integer \(k > 0\)
\algoutput Whether \((\exists \vec{v} \in  \cpre^*(\safe_k))[v_{q_0} \geq 0]\)
\begin{algorithmic}[1]
\State Possibly remove some useless states in \cA\label{alg:preproc}
\State Split states of \cA into boolean and nonboolean\label{alg:bool}
\State Let \texttt{Downset} be a type for downsets using a vector type that possibly has a
boolean part\label{alg:types}
\State Let \(S = \safe_k\) of type \texttt{Downset}
\State Compute a sufficient set \(E\) of  inputs\label{alg:inputs}
\State Compute the input-actions of \(E\)\label{alg:actions}
\While{true}
  \State Pick an input-action \(a\) of \(E\)\label{alg:pick}
  \If{no action is returned}
    \State \Return whether a vector in \(S\) maps \(q_0\) to a nonnegative value
  \EndIf
  \State \(S \leftarrow \cpre_a (S)\)
\EndWhile
\end{algorithmic}
\end{algorithm}

Our algorithm requires that the ``input-action picker'' used in line \ref{alg:pick}
decides whether we have reached a fixed point.  As the picker could check
whether \(S\) has changed, this is without loss of generality.

The computation of \(\cpre_a\) is the intuitive one, optimizations therein coming
from the internal representation of actions.  That is, it is implemented by
iterating through all io-actions compatible with \(a\), applying \(\bwd\) on
\(S\) for each of them, taking the union over all these applications, and finally
intersecting the result with \(S\).

\section{The many options at every line}\label{sec:implem}

The main computational costs of the algorithm are in finding input-actions and
computing \(\cpre_a\).  For the former, reducing the number of candidates is
crucial (by considering a good set of sufficient inputs).  For the latter,
reducing the size of the automaton (hence the dimension of the vectors) and
providing efficient data types for downsets is key.  Additionally, for the
``input-action picker'' to return an input that \emph{will} make progress, it
has to explore \(S\) in some way --- this can again be a costly operation that would
be sped up by better data structures for downsets.  Let us now review these
potential optimizations line by line.

\subsection{Preprocessing of the automaton (line \ref{alg:preproc})}\label{sec:preproc}

In this step, one can provide a heuristic that removes certain states that
do not contribute to the computation.  We provide an optional step that
detects \emph{surely losing states}, as presented in \cite{ggs14}.

\subsection{Boolean states (line \ref{alg:bool})}\label{sec:implem-bool}

We provide an implementation of the detection of boolean states, in addition to
an option to not detect them.  Our implementation is based on the concept of
\emph{bounded state}, as presented in \cite{bohy14}.  A state is \emph{bounded}
if it cannot be reached from a Büchi state that lies in a nontrivial strongly
connected component.  This can be detected in several ways, although it is not
an intrinsically costly operation.

\subsection{Vectors and downsets (line \ref{alg:types})}\label{sec:vecds}

The most basic data structure in the main algorithm is that of a vector used to
give a value to the states.  We provide a handful of different vector
classes:
\begin{compactitem}
\item Standard C++ vector and array types (\cinline{std::vector},\linebreak
  \cinline{std::array}).  Note that arrays are of fixed size; our implementation
  %automatically
  precompiles arrays of different sizes (up to \(300\) by default),
  and defaults to vectors if more entries are needed.
\item Vectors and arrays backed by SIMD\footnote{SIMD: Single Instruction
  Multiple Data, a set of CPU instructions \& registers to compute
  component-wise operations on fixed-size vectors.} registers.  This makes use of the
  type \cinline{std::experimental::simd} and leverages modern CPU
  optimizations.
\end{compactitem}

\vspace{.5em}

Additionally, all these implementations can be glued to an array of booleans
(\cinline{std::bitset}) to provide a type that combines boolean and integer
values.  These types can optionally expose an integer that is compatible with
the partial order (here, the sum of all the elements in the vector: if
\(\vec{u}\) dominates \(\vec{v}\), then the sum of the elements in \(\vec{u}\) is
larger than that of \(\vec{v}\)).  This value can help the downset implementations
in sorting the vectors.
%As a technical note, we disallowed these types to be
%copied implicitly: if a vector is inserted into a downset, then it is actually
%\emph{moved} there (\cinline{std::move}).

Downset types are built on top of a vector type.  We provide:
\begin{compactitem}
\item Implementations using sets or vectors of vectors, either containing only
  the dominating vectors, or containing explicitly all the vectors;
\item An implementation that relies on \(k\)-d trees, a space-partitioning data
  structure for organizing points in a \(k\)-dimensional space;~\cite{bcko08}
\item Implementations that store the vectors in specific bins depending on the
  %extra
  information exposed by the vector type.
\end{compactitem}

\subsection{Selecting sufficient inputs (line \ref{alg:inputs})}\label{sec:suff}

%\subsubsection{Terminal inputs and IOs}

Recall our discussion on sufficient inputs of Section~\ref{sec:sufficient}.  We
introduce the notion of \emph{terminal} IO following the intuition that there is
no restriction of the IO that would lead to a more specific action:
\begin{definition}
  An IO \(x\) is said to be \emph{terminal} if for every compatible IO \(y\), we
  have \(\ioact(x) \subseteq \ioact(y)\).  An \emph{input}~\(i\) is said to be
  \emph{terminal} if for every compatible input \(j\) we have
  \(\iact(i) \subseteq \iact(j)\).
\end{definition}

Our approaches to input selection focus on efficiently searching for a
sufficient set of terminal IOs and inputs.  The key property of terminal inputs
is that they are automatically valid, while still being more general than pure
inputs.
\begin{proposition}
  Any pure IO and any input is terminal.  Any terminal IO and any terminal input
  is valid.
\end{proposition}
\begin{proof}
  \emph{Any pure IO is terminal.}\quad Consider a pure IO \(x\) and a compatible IO
  \(y\).  If \((p, q) \in \ioact(x)\), then there is a transition
  \((p, z, q) \in \delta\) such that \(x\) is compatible with \(z\), and thus
  \(x \land z = x\).  Consequently, \(x \land z \land y = x \land y \neq \bot\), hence
  \(y\) and \(z\) are compatible and \((p, q) \in \ioact(y)\).  This shows that
  \(\ioact(x) \subseteq \ioact(y)\) and that \(x\) is terminal.

  \emph{Any pure input is terminal.}\quad Consider now a pure input \(i\) and a
  compatible input \(j\).  Let \(\ioact(x) \in \iact(i)\).  It holds that \(x\) is
  compatible with \(i\), hence \(i \land x \neq \bot\).  Since \(i\) is pure,
  \(i \land j = i\), thus \(i \land j \land x \neq \bot\), and \(x\) is also compatible with
  \(j\), implying that \(\ioact(x) \in \iact(j)\).  This shows that
  \(\iact(i) \subseteq \iact(j)\) and that \(i\) is terminal.

  \emph{Any terminal IO and input is valid.}\quad We prove the case for inputs, the
  IO case being similar.  Let \(i\) be a terminal input and \(j\) be a compatible
  pure input (at least one exists), then \(\iact(i) \subseteq \iact(j)\).  Since
  \(j\) is pure, it is also terminal, hence \(\iact(j) \subseteq \iact(i)\).  Hence
  \(\iact(i) = \iact(j)\) and \(i\) is valid.\qed
\end{proof}

%
% \begin{proposition}
%   For any set \(S\) of vectors:
%   \begin{itemize}
%   \item If \(x\) is a terminal IO, then for every compatible \emph{pure} IO \(y\),
%     \(\bwd(S, x) = \bwd(S, y)\).
%   \item If \(i\) is a terminal input, then for every compatible \emph{pure} input
%     \(j\), \(\cpre_i(S) = \cpre_j(S)\).
%   \end{itemize}
% \end{proposition}
% \begin{proof}
%   If \(x\) is a terminal IO and \(y\) is a compatible pure IO, then \(y\) is also
%   terminal, showing that \(\ioact(x) = \ioact(y)\).  Since \(\bwd(\cdot, x)\) only depends
%   on \(\ioact(x)\), this proves the statement.  This is similar for inputs, since
%   \(\cpre_i\) only depends on \(\iact(i)\).
% \end{proof}
%
%\subsubsection{Algorithms}
%
%For completeness, 
We present a simple algorithm for computing a sufficient set of terminal
IOs.  This is done by iteratively refining a set \(P\) of terminal IOs, starting
by assuming that \(\{\top\}\) is such a set and using any counterexample to split the
IOs:
\begin{algorithm}[H]
\caption{Computing a sufficient set of terminal IOs}
\label{alg:sufficient}
\alginput* A Büchi automaton \cA
\algoutput* A sufficient set of terminal IOs
\begin{algorithmic}
\State \(P \leftarrow \{\top\}\)
\For{every label \(x\) in the automaton}
  \For{every element \(y\) in \(P\)}
    \If{\(x \land y \neq \bot\)}
      \State Delete \(y\) from \(P\)
      \State Insert \(x \land y\) in \(P\)
      \If{\(\neg x \land y \neq \bot\)}
        insert \(\neg x \land y\) in \(P\)
      \EndIf
    \EndIf
  \EndFor
\EndFor
\State \Return \(P\)
\end{algorithmic}
\end{algorithm}
\vspace{.5em}

\noindent We provide 3 implementations of input selection:
\begin{compactitem}
\item No precomputation, i.e., return pure inputs/IOs;
\item Applying Algorithm~\ref{alg:sufficient} twice: for IOs and inputs;
\item Use a pure BDD approach to do the previous algorithm; this relies on extra
  variables to have the loop ``\textbf{for}\emph{ every element \(y\) in \(P\)}''
  iterate \emph{only} over elements \(y\) that satisfy \(x \land y \neq \bot\).
\end{compactitem}

\subsection{Precomputing actions (line \ref{alg:actions})}

Since computing \(\cpre_i\) for an input \(i\) requires to go through
\(\iact(i)\), possibly going back to the automaton and iterating through all
transitions, it may be beneficial to precompute this set.  We provide this step
as an optional optimization that is intertwined with the computation of a
sufficient set of IOs; for instance, rather than iterating through labels in
Algorithm~\ref{alg:sufficient}, one could iterate through all transitions, and
store the set of transitions that are compatible with each terminal IO on the
fly.

\subsection{Main loop: Picking input-actions (line \ref{alg:pick})}\label{sec:io}

We provide several implementations of the input-action picker:
\begin{compactitem}
\item Return each input-action in turn, until no change has occurred to \(S\)
  while going through all possible input-actions;
\item Search for an input-action that is certain to change \(S\).  This is based
  on the concept of \emph{critical input} as presented in~\cite{bohy14}.  This
  is reliant on how input-actions are ordered themselves, so we provide multiple
  options (using a priority queue to prefer inputs that were recently returned,
  randomize part of the array of input-actions, and randomize the whole array).
\end{compactitem}

\subsection{When are we done?}\label{sec:k}

The main algorithm answers either ``yes, the formula is realizable'' or ``don't
know.''  Indeed, for the value of \(k\) to provide an exact value, it has to be
very large and reaching a fixed point in the computation becomes impossible in
practice.  However, it is not necessary to restart the whole algorithm with
larger values of \(k\) in order to converge towards the correct answer: one can
just increase all the components of all the vectors in \(S\) (our main set), and
go back to the main loop.  There are thus two parameters that can be adjusted:
the starting value of \(k\) and the increment to \(S\) each time the loop is
restarted.

\section{Checking unrealizability of LTL specifications}\label{sec:unreal}

As mentioned in the preliminaries, for large values of $k$ the
\textbf{BackwardRealizability} problem is equivalent to a non-zero sum game
whose payoff set is the complement of the language of the given automaton.  More
precisely, for small values of $k$, a negative answer for the
\textbf{BackwardRealizability} problem does not imply that the output player
does not win the game. Instead, if one is interested in whether the output
player wins, a property known as determinacy~\cite{borel} can be leveraged to
instead ask whether a complementary property holds: does the input player win
the game?

We thus need to build an automaton \(\mathcal{B}\) for which a positive answer to
the \textbf{BackwardRealizability} translates to the previous property.  To do
so, we can consider the negation of the input formula, \(\neg\phi\), and inverse the
roles of the players, that is, swap the inputs and outputs.  However, to make
sure the semantics of the game is preserved, we also need to have the input
player play first, and the output player \emph{react} to the input player's
move.  To do so, we simply need to have the outputs moved \emph{one step
  forward} (in the future, in the LTL sense).  This can be done directly on the
input formula, by putting an \(X\) (neXt) operator on each output.  This can
however make the formula much more complex.

We propose an alternative to this: Obtain the automaton for \(\neg \phi\), then push the
outputs one state forward. This means that a transition \((p, \langle i, o \rangle, q)\) is
translated to a transition \((p, i, q)\), and the output \(o\) should be fired from
\(q\).  In practice, we would need to remember that output, and this would require
the construction to consider every state \((q, o)\), augmenting the number of
states tremendously.  Algorithm~\ref{alg:caddys-madness} for this task, however,
tries to minimize the number of states \((q, o)\) necessary by considering nonpure
outputs that maximally correspond to a pure input compatible with the
original transition label.

  \begin{algorithm}[H]
\caption{Modifying \cA so that the outputs are shifted forward}
\label{alg:caddys-madness}
\alginput* A Büchi automaton \cA with initial state $q_0$ and transition set \(\delta\)
\algoutput* The states $S$ and transitions $\Delta$ of the B\"uchi automaton $\mathcal{B}$
\begin{algorithmic}
\State \(S,V \leftarrow \{(q_0,\top)\}\)
\State \(\Delta \leftarrow \{\}\)
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \begin{algorithmic}
\While{\(V\) is nonempty}
  \State Pop $(p,o)$ from $V$
  \For{every \((p,x,q) \in \delta\)}
    \State $y \leftarrow x$
    \While{$y \neq \bot$} \Comment{Iterating through $x$'s minterms focusing on inputs}
      \State Let \(i\) be a pure input compatible with \(y\)
      \State \(o' \leftarrow \exists I.\, x \land i\) \Comment{Extract nonpure output compatible with \(i\)}
      \State Add $(\langle p, o\rangle, o \land i, \langle q, o'\rangle)$ to $\Delta$
      \State If $(q,o')$ is not in $S$, add it to $S$ and $V$
      \State $y \leftarrow y \land \lnot i$
    \EndWhile
  \EndFor
\EndWhile
\State \Return \(S,\Delta\)
\end{algorithmic}
\end{algorithm}

\section{Benchmarks}\label{sec:benchmarks}

\subsection{Protocol}

For the past few years, the yardstick of performance for synthesis tools is the
SYNTCOMP competition~\cite{syntcomp21}.  The organizers provide a bank of nearly a
thousand LTL formulas, and candidate tools are run with a time limit of one hour
on each of them.  The tool that solves the most instances in this timeframe wins
the competition.

To benchmark our tool, we relied on the 930 LTL formulas that were used in the
2021 SYNTCOMP competition, of which about 60\% are realizable.  Notably, 864 of
all the tests were solved in less than 20 seconds by some tool during the
competition, and among the 66 tests left out, 50 were not solved by any tool.
This showcases a usual trend of synthesis tools: either they solve an instance
fast, or they are unlikely to solve it at all.  To better focus on the fine
performance differences between the tools, we set a timeout of 60 seconds for
all tests.

We compared Acacia-Bonsai against itself using different choices of options, and
against Acacia+~\cite{bbfjr12}, Strix~\cite{msl18}, and
ltlsynt~\cite{duret.16.atva2,mc18}.  The benchmarks were completed on a
%headless
Linux computer with the following specifications:
\begin{compactitem}
\item CPU: Intel\textregistered{} Core\texttrademark{} i7-8700 CPU @ 3.20GHz.  This CPU
  has 6 hyperthreaded cores, meaning that 12 threads can run concurrently.  It
  supports Intel\textregistered{} AVX2, meaning that it has SIMD registers of up to
  256 bits.
\item Memory: The CPU has 12 MiB of cache, the computer has 16 GiB of DDR4-2666
  RAM.
\end{compactitem}

We present some of these results in the form of survival plots (also called
cactus plots).  They indicate how many instances can be solved within a set
time, where the time limit is for each instance.  As a rule of thumb, the lower
the curve, the better.  Since the tool tend to solve a lot of instances under
one second, we elected to present these graphics with a logarithmic y-axis.

\subsection{Results}

\paragraph{The options of Acacia-Bonsai.}  We compared 25 different
configurations of Acacia-Bonsai, in order to single out the best combination of
options.  We elected to start with some sensible defaults and test each
parameter by diverging from the defaults by a single option each time.
\begin{compactitem}
\item Preprocessing of the automaton (\Cref{sec:preproc}).  This has little
  impact, although a handful of tests saw an important boost.  Overall, the
  performance was slightly worse with automaton preprocessing, owing to the cost
  of computing the surely loosing states.  We elected to deactivate this option
  in our best configuration, as this allowed four more tests to pass.
\item Boolean states (\Cref{sec:implem-bool}).  This step allowed solving about
  5\% more tests when activated, globally.  
\item Vectors and downsets (\Cref{sec:vecds}).  Despite a wealth of different
  implementations, only the \(k\)-d tree implementation really stands out, in that
  it solves 5\% fewer tests than the rest.  The impact on using SIMD vectors and
  tailoring downset algorithms to leverage SIMD operations appears to be
  minimal.  This is likely caused by two factors: 1. The increasing ability for
  modern compilers to automatically identify where SIMD instructions can benefit
  performances; 2. The relative uselessness of pointwise vector operations in
  the task at hand.
\item Precomputing a sufficient set of inputs and IO (\Cref{sec:suff}).
  Computing that set using \Cref{alg:sufficient} turned out to offer the best
  performance, solving 23 more tests than using the pure inputs/IOs.  The
  pure BDD approach for this step was slightly more costly.
\item Picking input-actions (\Cref{sec:io}).  The approaches performed
  equivalently, with a slight edge for the choice of critical inputs without
  randomizing or priority queue.
\item Initial value and increments of \(k\) (\Cref{sec:k}).  We compared several
  combinations, which had little impact on overall performance, with the best
  one solving 3 more tests than the worst.
\item Unrealizability (\Cref{sec:unreal}). The following figure shows how the
  formula-based and the automaton-based approaches to unrealizability compare.
  We only show the unrealizable tests and add the configuration we use in
  practice: start two threads, one for each option, and stop as soon as one
  returns.
  \begin{figure}[h!]
    \centering\vspace{-2em}
    \includegraphics[width=0.7\textwidth]{unreal}\vspace{-1em}
    \caption{Reducing unrealizability to realizability.  Timeout set at 20
      seconds.}
    \label{fig:unreal}
  \end{figure}

  Despite the automaton-based approach showing better overall results, we note
  that this approach provides a larger automaton than the formula-based approach
  in about 99.5\% of the tests.  Additionally, the automaton-based approach
  offers better performances even when looking at the running time
  \emph{without} the formula-to-automaton part of the process.  This seems to
  indicate that the automaton that is produced is somewhat simpler for the main
  algorithm.
\end{compactitem}

\paragraph{Acacia-Bonsai and foes.}  The following plot shows the performance of
the tools together.  Within our parameters, Acacia-Bonsai solves 699 tests,
while Acacia+ solves 560, ltlsynt 703, and Strix 770.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\textwidth]{cactus}
  \caption{Survival plot for SYNTCOMP tools and Acacia-Bonsai}
  \label{fig:cactus}
\end{figure}

\paragraph{Instances solved by one tool but not the other.}  To better
understand the intrinsic algorithmic competitiveness of the different tools, we
study which instances were solved by our tool but not the others, and conversely:
\begin{itemize}
\item \emph{ltlsynt.}\quad This tool solves 4 more instances than Acacia-Bonsai
  overall.  It solves 61 instances on which Acacia-Bonsai times out, with less
  than a third of them being unrealizable instances.  It would be interesting to
  implement, within ltlsynt, the unrealizability techniques we describe in
  \Cref{sec:unreal}.
\item \emph{Strix.}\quad This tool solves 71 more instances than Acacia-Bonsai
  overall.  It solves 124 instances on which Acacia-Bonsai times out, 58\% of
  which are unrealizable.  For 90\% of these 124 instances, Strix answers in
  less than 2 seconds.  Conversely, of the instances on which Acacia-Bonsai
  answers while Strix times out, three quarters are solved within two seconds.
  This naturally hints at the possibility of combining the approaches of the two
  tools, using parallelization.
\end{itemize}

\section{Conclusion}

We provided multiple degrees of freedom in the main algorithm for downset-based
LTL realizability and implemented options for each of these degrees.  In this
paper, we presented the main ideas behind these.  Experiments show that this
careful reimplementation surpasses the performance of the original Acacia+,
making Acacia-Bonsai competitive against modern LTL realizability tools.  Along
with implementing some optimizations present in previous implementations, we
introduced several new ones: reduction of the input-output alphabet, alternative
antichain data structures, different strategies for input-picking, and
constructing a ``shifted automaton'' to test unrealizability.

A somewhat disappointing conclusion of our experiments concerns code that makes
explicit use of SIMD registers, i.e., large CPU registers that support pointwise
vector operations.  Our experiments indicate that downset-based algorithms and
downset data structures are not able to take full advantage of SIMD.  In the
future, we plan on investigating data structures for downsets that delay some of
their computations in order to better leverage vectorized operations.  Such a
data structure would not provide better theoretical performances, but would
potentially outperform our other data structures.

One surprise that prompts for further investigation is brought by our approach
to unrealizability (\Cref{sec:unreal}): we provided two options for processing
the input LTL formula into an automaton that expresses a realizable game iff the
original formula was \emph{un}realizable.  Although one option consistently
produces larger automata than the other, it appears that the downset-based
realizability algorithm performs better on the larger automata.  A close study
of the resulting automata may help in identifying salient features of automata
that are easier for the Acacia algorithm.

Lastly, we should note that this reimplementation of Acacia+ is not complete,
since a few options of Acacia+ have not yet been included in Acacia-Bonsai yet.
One such option consists in decomposing LTL formulas that are conjunctions of
subformulas into smaller instances of the realizability problem.  We plan on
implementing this before the next edition of SYNTCOMP.

\subsubsection*{Acknowledgements.}
We would like to thank \anon{V\'eronique Bruy\`ere} for recommending the use of
\(k\)-d trees as a data structure to store and manipulate downsets as well as
\anon{Cl\'ement Tamines} for useful conversations on these and alternative data
structures.  This research was partially funded by \anon{the FWO G030020N
  project ``SAILor''.}

\subsubsection*{Data-Availability Statement}
The software presented in this article and the analysed dataset are available
as~\cite{zenodo}.  In addition, the version under study is tagged in the GitHub
repository of this software as:\\
\centerline{\texttt{\url{https://github.com/gaperez64/acacia-bonsai/tree/TACAS23}}}

\bibliographystyle{splncs04}
\bibliography{refs}

\end{document}

% LocalWords:  Antichain LTL Realizability Michaël Cadilhac michael cadilhac
% LocalWords:  DePaul Pérez perez uantwerp SIMD antichains realizability
% LocalWords:  iteratively Downset downset downsets
